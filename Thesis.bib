Automatically generated by Mendeley Desktop 1.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{Losnegaard,
author = {Losnegaard, Gyri},
file = {:Users/snorre/Documents/Mendeley Desktop/Gyri Losnegaard -- Report Content Reuse project.doc:doc},
title = {{Automatic extraction of news text from online newspapers}}
}
@book{Wohlin2000,
 author = {Wohlin, Claes and Runeson, Per and H\"{o}st, Martin and Ohlsson, Magnus C. and Regnell, Bj\"{o}orn and Wessl{\'e}n, Anders},
 title = {Experimentation in Software Engineering: An Introduction},
 year = {2000},
 isbn = {0-7923-8682-5},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
}
@inproceedings{Moe2014compact,
  title={Compact trie clustering for overlap detection in news},
  author={Moe, Richard Elling and Elgesem, Dag},
  journal={Norsk informatikkonferanse (NIK)},
  volume={2013},
  year={2013},
  publisher={Akademika forlag}
}
@incollection{Moe2014,
year={2014},
isbn={978-3-319-06027-9},
booktitle={Advances in Information Retrieval},
volume={8416},
series={Lecture Notes in Computer Science},
editor={Rijke, Maarten and Kenter, Tom and Vries, ArjenP. and Zhai, ChengXiang and Jong, Franciska and Radinsky, Kira and Hofmann, Katja},
doi={10.1007/978-3-319-06028-6_73},
title={Improvements to Suffix Tree Clustering},
url={http://dx.doi.org/10.1007/978-3-319-06028-6_73},
publisher={Springer International Publishing},
author={Moe, Richard Elling},
pages={662-667}
}
@article{Larsen1999,
abstract = {Clustering is a powerful technique for large-scale topic discovery from text. It involves two phases: first, feature extraction maps each document or record to a point in high-dimensional space, then clustering algorithms automatically group the points into a hierarchy of clusters. We describe an unsupervised, near-linear time text clustering system that offers a number of algorithm choices for each phase. We introduce a methodology for measuring the quality of a cluster hierarchy in terms of F-Measure, and present the results of experiments comparing different algorithms. The evaluation considers some feature selection parameters (tfidfand feature vector length) but focuses on the clustering algorithms, suggest Scatter/Gather (buckshot, fractionation, and split/join) and k-means. Our experiments namely techniques that continuous center adjustment contributes more to cluster quality than seed selection does. It follows that using a simpler seed selection algorithm gives a better time/quality tradeoff. We describe a refinement to center adjustment, vector average damping, that further improves cluster quality. We also compare the near-linear time algorithms to a group average greedy agglomerative clustering algorithm to demonstrate the time/quality tradeoff quantitatively.},
author = {Larsen, Bjornar and Aone, Chinatsu},
doi = {10.1145/312129.312186},
editor = {Chaudhuri, Surajit and Madigan, David},
file = {:Users/snorre/Documents/Mendeley Desktop/Larsen, Aone - 1999 - Fast and effective text mining using linear-time document clustering.pdf:pdf},
isbn = {1581131437},
journal = {Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining KDD 99},
keywords = {clustering,multi document summarization,text mining},
number = {5},
pages = {16--22},
publisher = {ACM Press},
series = {KDD '99},
title = {{Fast and effective text mining using linear-time document clustering}},
url = {http://portal.acm.org/citation.cfm?doid=312129.312186},
volume = {5},
year = {1999}
}
@misc{GitHub2012,
author = {GitHub},
file = {:Users/snorre/Documents/Mendeley Desktop/GitHub - 2012 - GitHub.html:html},
title = {{GitHub}},
url = {https://github.com/},
urldate = {2012-04-25},
year = {2012}
}
@incollection{Haupt2004b,
abstract = {A continuous genetic algorithm is described. Several different continuous crossover schemes are described. Differences with the binary genetic algorithm are elucidated. A detailed demonstration problem indicates the excellent convergence of the continuous genetic algorithm.},
annote = {A continuous genetic algorithm is described. Several different continuous crossover schemes are described. Differences with the binary genetic algorithm are elucidated. A detailed demonstration problem indicates the excellent convergence of the continuous genetic algorithm.},
author = {Haupt, Randy L and Haupt, Sue Ellen},
booktitle = {Practical Genetic Algorithms},
doi = {10.1002/0471671746.ch3},
file = {:Users/snorre/Documents/Mendeley Desktop//Haupt, Haupt - 2004 - The Binary Genetic Algorithm.pdf:pdf},
isbn = {9780471671749},
keywords = {chromosome,continuous genetic algorithm,crossover,mating,mutation,mutation rate,real parameter genetic algorithm},
pages = {51--66},
publisher = {John Wiley \& Sons, Inc.},
title = {{The Continuous Genetic Algorithm}},
url = {http://dx.doi.org/10.1002/0471671746.ch3},
year = {2004}
}
@incollection{Manning2009,
abstract = {As recently as the 1990s, studies showed that most people preferred getting information from other people rather than from information retrieval sys- tems. Of course, in that time period, most people also used human travel agents to book their travel. However, during the last decade, relentless opti- mization of information retrieval effectivenesshas drivenweb search engines to new quality levels where most people are satisfied most of the time, and web search has become a standard and often preferred source of information finding. For example, the 2004 Pew Internet Survey (Fallows 2004) found that 92\% of Internet users say the Internet is a good place to go for getting everyday information. To the surprise of many, the field of information re- trieval has moved from being a primarily academic discipline to being the basis underlying most peoples preferredmeans of information access. This book presents the scientific underpinnings of this field, at a level accessible to graduate students as well as advanced undergraduates.},
author = {Manning, Christopher D and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
booktitle = {An Introduction to Information Retrieval},
chapter = {3},
file = {:Users/snorre/Documents/Mendeley Desktop/Manning, Raghavan, Sch\"{u}tze - 2009 - Wildcard queries.pdf:pdf},
isbn = {9783540857594},
number = {c},
organization = {Cambridge University Press Cambridge, England},
pages = {51 -- 56},
publisher = {Cambridge University Press},
title = {{Wildcard queries}},
url = {http://dspace.cusat.ac.in/dspace/handle/123456789/2538},
year = {2009}
}
@incollection{Haupt2004,
author = {Haupt, Randy L and Haupt, Sue Ellen},
booktitle = {Practical Genetic Algorithms},
doi = {10.1002/0471671746.ch1},
file = {:Users/snorre/Documents/Mendeley Desktop//Haupt, Haupt - 2004 - The Binary Genetic Algorithm.pdf:pdf},
isbn = {9780471671749},
keywords = {BFGS algorithm,DFP algorithm,Nelder-Mead downhill simplex method,genetic algorithms,line minimization,natural optimization,optimization,quasi-Newton methods,random search,root finding,steepest descent},
pages = {1--25},
publisher = {John Wiley \& Sons, Inc.},
title = {{Introduction to Optimization}},
url = {http://dx.doi.org/10.1002/0471671746.ch1},
year = {2004}
}
@book{Brownlee2011,
author = {Brownlee, Jason},
edition = {1},
file = {:Users/snorre/Documents/Mendeley Desktop/Brownlee - 2011 - Clever Algorithms Nature-Inspired Programming Recipes.pdf:pdf},
isbn = {978-1-4467-8506-5},
pages = {423},
title = {{Clever Algorithms Nature-Inspired Programming Recipes}},
year = {2011}
}
@inproceedings{Chuan2003,
abstract = {In most of the modern information retrieval (IR) systems, such as Okapi system, there are a variety of parameters to be turned which are data-dependent and sensitive. Manual parameter setting with fixed experimental values is not always feasible and reliable in practical cases. Furthermore, the supervised learning approaches are not applicable for lacking of relevant information while retrieving. Therefore, an automatic unsupervised parameter learning mechanism is necessary and important. In this paper, a genetic algorithm (GA) based parameter optimization approach is proposed and experimented on Okapi system using large scale data sets of TREC11, TREC10 and TREC9 web track collections. It indicates that our algorithm is effective to adjust system parameters and improve the retrieval performance significantly.},
author = {Chuan, Lin and Shao-ping, Ma and Min, Zhang},
booktitle = {Systems, Man and Cybernetics, 2003. IEEE International Conference on},
file = {:Users/snorre/Documents/Mendeley Desktop//Chuan, Shao-ping, Min - 2003 - Parameter optimization for information retrieval with genetic algorithm.pdf:pdf},
isbn = {1062-922X},
keywords = {Okapi system,TREC10,TREC11,TREC9,automatic unsupervised parameter learning,genetic algorithm,genetic algorithms,information retrieval,large scale data sets,parameter optimization,unsupervised learning,web track collections},
month = oct,
pages = {3822--3827},
title = {{Parameter optimization for information retrieval with genetic algorithm}},
url = {http://dx.doi.org/10.1109/ICSMC.2003.1244484},
volume = {4},
year = {2003}
}
@incollection{Baeza-Yates2011c,
author = {Baeza-Yates, Ricardo and Ribeiro-Neto, Berthier},
booktitle = {Modern Information Retrieval: The Concepts and Technology Behind Search (ACM Press Books)},
chapter = {9 Indexing},
edition = {2},
isbn = {0321416910},
pages = {360 -- 372},
publisher = {Addison Wesley},
title = {{Suffix Trees and Suffix Arrays}},
year = {2011}
}
@book{VanRijsbergen1979,
address = {London},
author = {{Van Rijsbergen}, C J},
booktitle = {Information retrieval},
edition = {2},
file = {:Users/snorre/Documents/Mendeley Desktop/Van Rijsbergen - 1979 - Automatic Classification.pdf:pdf},
pages = {23 -- 47},
publisher = {Butterworths},
title = {{Automatic Classification}},
year = {1979}
}
@article{5560625,
abstract = {Case studies of 17 organizations that have used agile methods for more than three years uncovered many serious "people" challenges including recruitment, training, motivation, and performance evaluation.},
author = {Conboy, K and Coyle, S and Wang, Xiaofeng and Pikkarainen, M},
doi = {10.1109/MS.2010.132},
file = {:Users/snorre/Documents/Mendeley Desktop/Conboy et al. - 2011 - People over Process Key Challenges in Agile Development.pdf:pdf},
issn = {0740-7459},
journal = {Software, IEEE},
keywords = {agile development,motivation,organisational aspects,organisations,performance evaluation,recruitment,training},
number = {4},
pages = {48--57},
title = {{People over Process: Key Challenges in Agile Development}},
volume = {28},
year = {2011}
}
@article{Chim2008,
abstract = {In this paper, we propose a phrase-based document similarity to compute the pair-wise similarities of documents based on the suffix tree document (STD) model. By mapping each node in the suffix tree of STD model into a unique feature term in the vector space document (VSD) model, the phrase-based document similarity naturally inherits the term tf-idf weighting scheme in computing the document similarity with phrases. We apply the phrase-based document similarity to the group-average Hierarchical Agglomerative Clustering (HAC) algorithm and develop a new document clustering approach. Our evaluation experiments indicate that, the new clustering approach is very effective on clustering the documents of two standard document benchmark corpora OHSUMED and RCV1. The quality of the clustering results significantly surpass the results of traditional single-word textit\{tf-idf\} similarity measure in the same HAC algorithm, especially in large document data sets. Furthermore, by studying the property of STD model, we conclude that the feature vector of phrase terms in the STD model can be considered as an expanded feature vector of the traditional single-word terms in the VSD model. This conclusion sufficiently explains why the phrase-based document similarity works much better than the single-word tf-idf similarity measure.},
author = {Chim, Hung and Deng, Xiaotie},
doi = {10.1109/TKDE.2008.50},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {document clustering,feature vector,group-average hierarchical agglomerative clusterin,pair-wise document similarity,pattern clustering,phrase-based document similarity,suffix tree document model,text analysis,trees (mathematics),vector space document model},
month = sep,
number = {9},
pages = {1217--1229},
title = {{Efficient Phrase-Based Document Similarity for Clustering}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4459328},
volume = {20},
year = {2008}
}
@incollection{Baeza-Yates2011a,
author = {Baeza-Yates, Ricardo and Ribeiro-Neto, Berthier},
booktitle = {Modern Information Retrieval: The Concepts and Technology Behind Search (ACM Press Books)},
chapter = {8},
edition = {2},
isbn = {0321416910},
pages = {281--335},
publisher = {Addison Wesley},
title = {{Text Classification}},
year = {2011}
}
@incollection{Haupt2004a,
abstract = {Examples are used to introduce application of a simple binary genetic algorithm. This chapter discusses variable encoding and decoding, initializing the population, natural selection, mating, mutation, and convergence. A detailed step-by-step example of finding the maximum of a multi-modal function is given.},
annote = {Examples are used to introduce application of a simple binary genetic algorithm. This chapter discusses variable encoding and decoding, initializing the population, natural selection, mating, mutation, and convergence. A detailed step-by-step example of finding the maximum of a multi-modal function is given.},
author = {Haupt, Randy L and Haupt, Sue Ellen},
booktitle = {Practical Genetic Algorithms},
doi = {10.1002/0471671746.ch2},
file = {:Users/snorre/Documents/Mendeley Desktop//Haupt, Haupt - 2004 - The Binary Genetic Algorithm.pdf:pdf},
isbn = {9780471671749},
keywords = {binary genetic algorithm,chromosome,cost weighting,crossover,decoding,encoding,gene,mating,mutation,mutation rate,natural selection,offspring,population,rank weighting,roulette wheel selection,simple genetic algorithm,tournament selection},
pages = {27--50},
publisher = {John Wiley \& Sons, Inc.},
title = {{The Binary Genetic Algorithm}},
url = {http://dx.doi.org/10.1002/0471671746.ch2},
year = {2004}
}
@book{Voorhees2005,
author = {Voorhees, E and Harman, D K and, National Institute of Standards and Technology (US)},
file = {:Users/snorre/Documents/Mendeley Desktop/Voorhees et al. - 2005 - TREC Experiment and evaluation in information retrieval.pdf:pdf},
publisher = {MIT press Cambridge\^{} eMA MA},
title = {{TREC: Experiment and evaluation in information retrieval}},
volume = {63},
year = {2005}
}
@article{Yang1999,
abstract = {This paper focuses on a comparative evaluation of a wide-range of text categorization methods, including previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration variations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that exclude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performance; except for a Naive Bayes approach, the other learning algorithms also performed relatively well.},
annote = {10.1023/A:1009982220290},
author = {Yang, Yiming},
file = {:Users/snorre/Documents/Mendeley Desktop//Yang - 1999 - An Evaluation of Statistical Approaches to Text Categorization.pdf:pdf},
issn = {1386-4564},
journal = {Information Retrieval},
number = {1},
pages = {69--90},
publisher = {Springer Netherlands},
title = {{An Evaluation of Statistical Approaches to Text Categorization}},
url = {http://dx.doi.org/10.1023/A:1009982220290},
volume = {1},
year = {1999}
}
@misc{Zadrozny2012,
author = {Zadrozny, Fabio},
file = {:Users/snorre/Documents/Mendeley Desktop/Zadrozny - 2012 - PyDev - Python IDE for Eclipse Eclipse Plugins, Bundles and Products - Eclipse Marketplace.html:html},
title = {{PyDev - Python IDE for Eclipse | Eclipse Plugins, Bundles and Products - Eclipse Marketplace}},
url = {http://marketplace.eclipse.org/content/pydev-python-ide-eclipse},
urldate = {2012-12-04},
year = {2012}
}
@article{Rafi2011,
author = {Rafi, M and Maujood, M and Fazal, M M and Ali, S M},
file = {:Users/snorre/Documents/Mendeley Desktop/Rafi et al. - 2011 - A comparison of two suffix tree-based document clustering algorithms.pdf:pdf},
journal = {Arxiv preprint arXiv:1112.6222},
title = {{A comparison of two suffix tree-based document clustering algorithms}},
year = {2011}
}
@article{Sebastiani2002,
address = {New York, NY, USA},
author = {Sebastiani, Fabrizio},
doi = {http://doi.acm.org/10.1145/505282.505283},
file = {:Users/snorre/Documents/Mendeley Desktop/Sebastiani - 2002 - Machine learning in automated text categorization.pdf:pdf},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
keywords = {Machine learning,text categorization,text classification},
month = mar,
number = {1},
pages = {1--47},
publisher = {ACM},
title = {{Machine learning in automated text categorization}},
url = {http://doi.acm.org/10.1145/505282.505283},
volume = {34},
year = {2002}
}
@incollection{Negnevitsky2002,
author = {Negnevitsky, Michael},
booktitle = {Artificial Intelligence: A Guide to Intelligent Systems},
edition = {1},
isbn = {0201-71159-1},
pages = {217 -- 254},
publisher = {Addison Wesley; 1 edition},
title = {{Evolutionary computation}},
year = {2002}
}
@article{gulla2008contextualized,
author = {Gulla, J A and Borch, H O and Ingvaldsen, J E},
journal = {Emerging technologies of text mining: techniques and applications},
pages = {184},
publisher = {Information Science Publishing},
title = {{Contextualized Clustering in Exploratory Web Search}},
year = {2008}
}
@article{Numaker1990,
abstract = {In this paper, the use of systems development as a methodology in information systems (IS) research is described and defended. A framework to explain the nature of systems development as a research methodology in IS research is proposed. Use of this methodology in the engineering field in general is compared with its use specifically in computer science and computer engineering. An integrated program for conducting IS research that incorporates theory building, systems development, experimentation, and observation is proposed. Progress in several application domains is reviewed to provide a basis upon which to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, which is the basic method of applying the systems development research methodology, is then discussed. It is the authors' belief that systems development and other research methodologies are complementary and that an integrated multi-dimensional and multimethodological approach will generate fruitful IS research results. The premise is that research contributions can result from systems development, experimentation, observation, and performance testing of the systems under development and that all of these research approaches are needed to investigate different aspects of the research question.},
author = {Jr., Jay F Nunamaker and Chen, Minder and Purdin, Titus D M},
file = {:Users/snorre/Documents/Mendeley Desktop/Jr., Chen, Purdin - 1990 - Systems Development in Information Systems Research.pdf:pdf},
issn = {07421222},
journal = {Journal of Management Information Systems},
number = {3},
pages = {pp. 89--106},
publisher = {M.E. Sharpe, Inc.},
title = {{Systems Development in Information Systems Research}},
url = {http://www.jstor.org/stable/40397957},
volume = {7},
year = {1990}
}
@article{Lewis2004,
abstract = {Reuters CorpusVolume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters doc- umentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illus- trating the collections properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.},
author = {Lewis, David D and Yang, Yiming and Rose, Tony G and Li, Fan},
doi = {10.1145/122860.122861},
file = {:Users/snorre/Documents/Mendeley Desktop/Lewis et al. - 2004 - RCV1 A New Benchmark Collection for Text Categorization Research.pdf:pdf},
isbn = {0897914481},
issn = {15337928},
journal = {Corpus},
pages = {361--397},
publisher = {JMLR. org},
title = {{RCV1: A New Benchmark Collection for Text Categorization Research}},
url = {http://portal.acm.org/citation.cfm?id=1005345},
volume = {5},
year = {2004}
}
@incollection{Baeza-Yates2011b,
author = {Baeza-Yates, Ricardo and Ribeiro-Neto, Berthier},
booktitle = {Modern Information Retrieval: The Concepts and Technology Behind Search (ACM Press Books)},
chapter = {4},
edition = {2},
isbn = {0321416910},
pages = {131 -- 176},
publisher = {Addison Wesley},
title = {{Retrieval Evaluation}},
year = {2011}
}
@misc{UniversityofGlasgow2012,
author = {{University of Glasgow}},
file = {:Users/snorre/Documents/Mendeley Desktop/University of Glasgow - 2012 - access to web research collections wt2gwt10ggovgov2blog06blog08.html:html},
title = {access to web research collections wt2g/wt10g/gov/gov2/blog06/blog08},
url = {http://ir.dcs.gla.ac.uk/test\_collections/access\_to\_data.html},
urldate = {2012-02-27},
year = {2012}
}
@inproceedings{Chim2007,
address = {New York, NY, USA},
author = {Chim, Hung and Deng, Xiaotie},
booktitle = {Proceedings of the 16th international conference on World Wide Web},
doi = {10.1145/1242572.1242590},
isbn = {978-1-59593-654-7},
keywords = {document model,similarity measure,suffix tree},
pages = {121--130},
publisher = {ACM},
series = {WWW '07},
title = {{A new suffix tree similarity measure for document clustering}},
url = {http://doi.acm.org/10.1145/1242572.1242590},
year = {2007}
}
@inproceedings{Oren1998,
address = {Melbourne, Australia},
annote = {290956
46-54},
author = {Zamir, Oren and Etzioni, Oren},
booktitle = {Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval},
doi = {10.1145/290941.290956},
file = {:Users/snorre/Documents/Mendeley Desktop/Zamir, Etzioni - 1998 - Web document clustering a feasibility demonstration.pdf:pdf},
publisher = {ACM},
title = {{Web document clustering: a feasibility demonstration}},
url = {http://dx.doi.org/10.1145/290941.290956},
year = {1998}
}
@misc{Lewis2004a,
author = {Lewis, David D.},
file = {:Users/snorre/Documents/Mendeley Desktop/Lewis - 2004 - Reuters-21578 Text Categorization Test Collection.html:html},
title = {{Reuters-21578 Text Categorization Test Collection}},
url = {http://www.daviddlewis.com/resources/testcollections/reuters21578/},
urldate = {2012-03-18},
year = {2004}
}
@inproceedings{Zakos2005,
abstract = {In this paper we present an approach based on the application of an evolutionary algorithm to optimally tune the parameters of a novel technique for effective Web information retrieval. Context matching is a context-based technique for the ad-hoc retrieval of Web documents that relies on a number of inter-related parameters that define the nature of the context it uses. Its aim is to dynamically generate a context-based measure of term significance during retrieval that can be used as an indicator of document relevancy and ultimately contribute to a documents rank score. But the optimal setting of context matching parameters is an important aspect of the technique to ensure effective retrieval. Thus, the goal of this paper is to investigate the use of an evolutionary algorithm for the optimization of context matching parameters and compare its performance to an iterative technique that exhaustively explores combinations of parameters. We show how the most effective settings for parameters are obtained efficiently through the evolutionary algorithm. We also show how context matching, through the use of these optimized parameters, achieves effective retrieval results on benchmark data that are a significant improvement on previously published results.},
author = {Zakos, J and Ping, Zhang and Verma, B},
booktitle = {Neural Networks, 2005. IJCNN '05. Proceedings. 2005 IEEE International Joint Conference on},
file = {:Users/snorre/Documents/Mendeley Desktop//Zakos, Ping, Verma - 2005 - Optimization of parameters for effective Web information retrieval using an evolutionary algorithm.pdf:pdf},
keywords = {Internet,Web information retrieval,content-based retrieval,context matching,document rank scoriong,document relevancy,evolutionary algorithm,evolutionary computation,iterative methods,iterative technique,parameter optimization,relevance feedback},
pages = {582--587 vol. 1},
title = {{Optimization of parameters for effective Web information retrieval using an evolutionary algorithm}},
url = {http://dx.doi.org/10.1109/IJCNN.2005.1555896},
volume = {1},
year = {2005}
}
@article{vonHevner2004,
author = {Hevner, A R and March, S T and Park, J and Ram, S},
file = {:Users/snorre/Documents/Mendeley Desktop/Hevner et al. - 2004 - Design science in information systems research.pdf:pdf},
journal = {Mis Quarterly},
number = {1},
pages = {75--105},
title = {{Design science in information systems research}},
volume = {28},
year = {2004}
}
@misc{ElgesemMoe2013,
author = {Moe, Richard Elling and Elgesem, Dag},
file = {:Users/snorre/Documents/Mendeley Desktop/NIKMoeElgesemRevised.pdf:pdf},
publisher = {University of Bergen},
title = {{Compact trie clustering for overlap detection in news}},
year = {2013}
}
@article{Bartz-Beielstein2004,
abstract = {We propose a highly flexible sequential methodology for the experimental analysis of optimization algorithms. The proposed technique employs computational statistic methods to investigate the interactions among optimization problems, algorithms, and environments. The workings of the proposed technique are illustrated on the parameterization and comparison of both a population–based and a direct search algorithm, on a well–known benchmark problem, as well as on a simplified model of a real–world problem. Experimental results are reported and conclusions are derived. (© 2004 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
author = {Bartz–Beielstein, T and Parsopoulos, K E and Vrahatis, M N},
doi = {10.1002/anac.200410007},
file = {:Users/snorre/Documents/Mendeley Desktop/Bartz–Beielstein, Parsopoulos, Vrahatis - 2004 - Design and Analysis of Optimization Algorithms Using Computational Statistics.pdf:pdf},
issn = {1611-8189},
journal = {Applied Numerical Analysis \& Computational Mathematics},
keywords = {Key word},
number = {2},
pages = {413--433},
publisher = {WILEY-VCH Verlag},
title = {{Design and Analysis of Optimization Algorithms Using Computational Statistics}},
url = {http://dx.doi.org/10.1002/anac.200410007},
volume = {1},
year = {2004}
}
@inproceedings{Lewis1991,
author = {Lewis, D D},
booktitle = {Proceedings of Speech and Natural Language Workshop},
file = {:Users/snorre/Documents/Mendeley Desktop//Lewis - 1991 - Evaluating text categorization.pdf:pdf},
pages = {312--318},
title = {{Evaluating text categorization}},
year = {1991}
}
@article{Horng2000,
abstract = {This paper proposes a novel approach to automatically retrieve keywords and then uses genetic algorithms to adapt the keyword weights. One of the contributions of the paper is to combine the Bigram (Chen, A., He, J., Xu, L., Gey, F. C., \& Meggs, J. 1997. Chinese text retrieval without using a dictionary, ACM SIGIR’97, Philadelphia, PA, USA, pp. 42–49; Yang, Y.-Y., Chang, J.-S., \& Chen, K.-J. 1993), Document automatic classification and ranking, Master thesis, Department of Computer Science, National Tsing Hua University) model and PAT-tree structure (Chien, L.-F., Huang, T.-I., \& Chien, M.-C. 1997 Pat-tree-based keyword extraction for Chinese information retrieval, ACM SIGIR’97, Philadelphia, PA, US, pp. 50–59) to retrieve keywords. The approach extracts bigrams from documents and uses the bigrams to construct a PAT-tree to retrieve keywords. The proposed approach can retrieve any type of keywords such as technical keywords and a person’s name. Effectiveness of the proposed approach is demonstrated by comparing how effective are the keywords found by both this approach and the PAT-tree based approach. This comparison reveals that our keyword retrieval approach is as accurate as the PAT-tree based approach, yet our approach is faster and uses less memory. The study then applies genetic algorithms to tune the weight of retrieved keywords. Moreover, several documents obtained from web sites are tested and experimental results are compared with those of other approaches, indicating that the proposed approach is highly promising for applications.},
author = {Horng, Jorng-Tzong and Yeh, Ching-Chang},
doi = {10.1016/S0306-4573(00)00008-X},
issn = {03064573},
journal = {Information Processing \& Management},
keywords = {information retrieval,keyword,pat-tree},
month = sep,
number = {5},
pages = {737--759},
title = {{Applying genetic algorithms to query optimization in document retrieval}},
url = {http://dx.doi.org/10.1016/S0306-4573(00)00008-X},
volume = {36},
year = {2000}
}
@misc{NationalInstituteofStandardsandTechnology2004,
annote = {
        

      },
author = {{National Institute of Standards and Technology}},
file = {:Users/snorre/Documents/Mendeley Desktop/National Institute of Standards and Technology - 2004 - reuters corpora @ nist.html:html},
title = {reuters corpora @ nist},
url = {http://trec.nist.gov/data/reuters/reuters.html},
urldate = {2012-03-18},
year = {2004}
}
@misc{UniversityofBergen,
annote = {logikk, informasjon og interaksjon},
author = {{University of Bergen}},
editor = {Myking, Ingar},
file = {:Users/snorre/Documents/Mendeley Desktop/University of Bergen - Unknown - Logikk, informasjon og interaksjon UiB.html:html},
keywords = {forskergruppe,informasjon og interaksjon,logikk,universitetet i bergen},
title = {{Logikk, informasjon og interaksjon :: UiB}},
url = {http://www.uib.no/fg/lii},
urldate = {2012-03-17}
}
@misc{Macdonald2011,
author = {Macdonald, Craig},
file = {:Users/snorre/Documents/Mendeley Desktop/Macdonald - 2011 - TREC-BLOG - Information Retrieval Wiki.html:html},
title = {{TREC-BLOG - Information Retrieval Wiki}},
url = {http://ir.dcs.gla.ac.uk/wiki/TREC-BLOG},
urldate = {2012-03-18},
year = {2011}
}
@misc{Elgesem2009,
author = {Elgesem, Dag},
file = {:Users/snorre/Documents/Mendeley Desktop/Elgesem - 2009 - Resirkulering av nyheter I nettavisene 1999 – 2009.pdf:pdf},
title = {{Resirkulering av nyheter I nettavisene 1999 – 2009}},
year = {2009}
}
@article{Cleverdon1966,
author = {Cleverdon, C W and Mills, J and Keen, M},
file = {:Users/snorre/Documents/Mendeley Desktop/Cleverdon, Mills, Keen - 1966 - Factors determining the performance of indexing systems.pdf:pdf},
journal = {ASLIB Cranfield project, Cranfield},
keywords = {todo},
title = {{Factors determining the performance of indexing systems}},
url = {https://dspace.lib.cranfield.ac.uk/handle/1826/863},
year = {1966}
}
@article{Sutcliffe1998,
abstract = {A framework for constructing a cognitive model of users' information searching behaviour is described. The motivation for the framework is to create explanatory and predictive theories of information searching to improve the design of information retrieval (IR) systems. The framework proposes a taxonomy of components for process models of the information seeking task, information need types and knowledge sources necessary to support the task. The framework is developed into a preliminary version of a cognitive theory of information searching by the addition of strategies and correspondence rules which predict user behaviour in different task stages according to information need types, facilities provided by the IR system and knowledge held by the user. The theory is evaluated by using claims analysis based on empirical observations of users information retrieval and by a walkthrough of an IR session to investigate how well the theory can account for empirical evidence. Results show that the theory can indicate the expert strategies which should be followed in different task contexts but predictions of actual user behaviour are less accurate. The future possibilities for employing the theoretical model as a tutorial advisor for information retrieval and as an evaluation method for IR systems are reviewed. The role and potential of cognitive theories of user task-action in Information Retrieval and Human Computer Interaction are discussed.},
annote = {HCI and Information Retrieval},
author = {Sutcliffe, Alistair and Ennis, Mark},
doi = {10.1016/S0953-5438(98)00013-7},
issn = {0953-5438},
journal = {Interacting with Computers},
keywords = {Scenarios},
number = {3},
pages = {321--351},
title = {{Towards a cognitive theory of information retrieval}},
url = {http://www.sciencedirect.com/science/article/pii/S0953543898000137},
volume = {10},
year = {1998}
}
@inproceedings{Kennedy1995,
abstract = {A concept for the optimization of nonlinear functions using particle swarm methodology is introduced. The evolution of several paradigms is outlined, and an implementation of one of the paradigms is discussed. Benchmark testing of the paradigm is described, and applications, including nonlinear function optimization and neural network training, are proposed. The relationships between particle swarm optimization and both artificial life and genetic algorithms are described},
author = {Kennedy, J and Eberhart, R},
booktitle = {Neural Networks, 1995. Proceedings., IEEE International Conference on},
doi = {10.1109/ICNN.1995.488968},
file = {:Users/snorre/Documents/Mendeley Desktop/Kennedy, Eberhart - 1995 - Particle swarm optimization.pdf:pdf},
keywords = {artificial intelligence,artificial life,evolution,genetic algorithms,multidimensional search,neural nets,neural network,nonlinear functions,optimization,particle swarm,search problems,simulation,social metaphor},
pages = {1942 --1948},
title = {{Particle swarm optimization}},
volume = {4},
year = {1995}
}
@misc{Vaishnavi2004,
author = {Vaishnavi, V and Kuechler, W},
title = {{Design Science Research in Information Systems}},
url = {http://www.desrist.org/desrist},
urldate = {2012-03-08},
year = {2004}
}
@article{Opdahl2009,
abstract = {A number of methods have been proposed or adapted to include security in the requirements analysis stage, but the industrial take-up has been limited and there are few empirical and comparative evaluations. This paper reports on a pair of controlled experiments that compared two methods for early elicitation of security threats, namely attack trees and misuse cases. The 28 and 35 participants in the two experiments solved two threat identification tasks individually by means of the two techniques, using a Latin-Squares design to control for technique and task order. The dependent variables were effectiveness of the techniques measured as the number of threats found, coverage of the techniques measured in terms of the types of threats found and perceptions of the techniques measured through a post-task questionnaire based on the Technology Acceptance Model. The only difference was that, in the second experiment, the participants were given a pre-drawn use-case diagram to use as a starting point for solving the tasks. In the first experiment, no pre-drawn use-case diagram was provided. The main finding was that attack trees were more effective for finding threats, in particular when there was no pre-drawn use-case diagram. However, the participants had similar opinions of the two techniques, and perception of a technique was not correlated with performance with that technique. The study underlines the need for further comparisons in a broader range of settings involving additional techniques, and it suggests several concrete experiments and other paths for further work.},
annote = {SPECIAL ISSUE: Model-Driven Development for Secure Information Systems},
author = {Opdahl, Andreas L and Sindre, Guttorm},
doi = {10.1016/j.infsof.2008.05.013},
file = {:Users/snorre/Documents/Mendeley Desktop/Opdahl, Sindre - 2009 - Experimental comparison of attack trees and misuse cases for security threat identification.pdf:pdf},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = {Experiments},
number = {5},
pages = {916--932},
title = {{Experimental comparison of attack trees and misuse cases for security threat identification}},
url = {http://www.sciencedirect.com/science/article/pii/S0950584908000773},
volume = {51},
year = {2009}
}
@inproceedings{Oren1997,
author = {Zamir, Oren and Etzioni, Oren and Madani, Omid and Karp, Richard M},
booktitle = {Proceedings of the Third International Conference on Knowledge Discovery and Data Mining},
file = {:Users/snorre/Documents/Mendeley Desktop/Zamir et al. - 1997 - Fast and Intuitive Clustering of Web Documents(2).pdf:pdf},
title = {{Fast and Intuitive Clustering of Web Documents}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.9803},
year = {1997}
}
@article{Zhao2005,
abstract = {Fast and high-quality document clustering algorithms play an important role in providing intuitive navigation and browsing mechanisms by organizing large amounts of information into a small number of meaningful clusters. In particular, clustering algorithms that build meaningful hierarchies out of large document collections are ideal tools for their interactive visualization and exploration as they provide data-views that are consistent, predictable, and at different levels of granularity. This paper focuses on document clustering algorithms that build such hierarchical solutions and (i) presents a comprehensive study of partitional and agglomerative algorithms that use different criterion functions and merging schemes, and (ii) presents a new class of clustering algorithms called constrained agglomerative algorithms , which combine features from both partitional and agglomerative approaches that allows them to reduce the early-stage errors made by agglomerative methods and hence improve the quality of clustering solutions. The experimental evaluation shows that, contrary to the common belief, partitional algorithms always lead to better solutions than agglomerative algorithms; making them ideal for clustering large document collections due to not only their relatively low computational requirements, but also higher clustering quality. Furthermore, the constrained agglomerative methods consistently lead to better solutions than agglomerative methods alone and for many cases they outperform partitional methods, as well.},
annote = {10.1007/s10618-005-0361-3},
author = {Zhao, Ying and Karypis, George and Fayyad, Usama},
file = {:Users/snorre/Documents/Mendeley Desktop/Zhao, Karypis, Fayyad - 2005 - Hierarchical Clustering Algorithms for Document Datasets.pdf:pdf},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
number = {2},
pages = {141--168},
publisher = {Springer Netherlands},
title = {{Hierarchical Clustering Algorithms for Document Datasets}},
url = {http://dx.doi.org/10.1007/s10618-005-0361-3},
volume = {10},
year = {2005}
}
@incollection{Manning2009a,
abstract = {Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval, including web search and the related areas of text classification and text clustering from basic concepts. Written from a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the book has been carefully structured in order to make teaching more natural and effective. Although originally designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a buzz for researchers and professionals alike.},
archivePrefix = {arXiv},
arxivId = {0521865719 9780521865715},
author = {Manning, Christopher D. and Raghavan, Prabhakar},
booktitle = {An Introduction to Information Retrieval},
chapter = {6},
doi = {10.1109/LPT.2009.2020494},
editor = {Salas, A Cannon-Bowers E},
eprint = {0521865719 9780521865715},
file = {:Users/snorre/Documents/Mendeley Desktop/Manning, Raghavan - 2009 - Scoring, term weighting and the vector space model.pdf:pdf},
isbn = {0521865719},
issn = {13864564},
keywords = {keyword},
organization = {Cambridge University Press Cambridge, England},
pages = {1},
pmid = {10575050},
publisher = {Cambridge University Press},
title = {{Scoring, term weighting and the vector space model}},
url = {http://dspace.cusat.ac.in/dspace/handle/123456789/2538},
year = {2009}
}
@misc{Reutersa,
author = {Reuters},
file = {:Users/snorre/Documents/Mendeley Desktop/Reuters - Unknown - Reuters Corpus.html:html},
title = {{Reuters Corpus}},
url = {http://about.reuters.com/researchandstandards/corpus/},
urldate = {2012-04-16}
}
@book{Goldberg1989,
abstract = {David Goldberg's Genetic Algorithms in Search, Optimization and Machine Learning is by far the bestselling introduction to genetic algorithms. Goldberg is one of the preeminent researchers in the field-he has published over 100 research articles on genetic algorithms and is a student of John Holland, the father of genetic algorithms-and his deep understanding of the material shines through. The book contains a complete listing of a simple genetic algorithm in Pascal, which C programmers can easily understand. The book covers all of the important topics in the field, including crossover, mutation, classifier systems, and fitness scaling, giving a novice with a computer science background enough information to implement a genetic algorithm and describe genetic algorithms to a friend.},
author = {Goldberg, D E},
editor = {Addison-Wesley},
isbn = {0201157675},
keywords = {buzz,fizz},
mendeley-tags = {buzz,fizz},
pages = {432},
publisher = {Addison-Wesley},
title = {{Genetic Algorithms in Search, Optimization, and Machine Learning}},
year = {1989}
}
